# twitter_api-data-gathering-wrangling-cassessing-cleaning-and-visualization
##Project Summary

This project aims to give to the student a real case of how to gather, assess, clean, and analyze the data, in other words its englobes the Data Wrangling and Exploratory Data Analysis. The database used as an example is about the @dog_rate user from Twitter, as known as WeRateDogsâ„¢.

The Data Gathering process bundled three different tasks, the first one download file from URL and later loading to the Jupyter Notebook, which requires a manual step, the second downloading a file programmatically, and the third gathering data from the Twitter API. This step has also required to save these data in a local machine.

Based on the data gathered, I have assessed the most evident issues (17 issues in total) and documented it to create a record of modifications. Later, in Data Cleaning process I have fixed all identified issues, and I have also merged (the two downloaded files from the Data Gathering process) into one and added some missing values (from the archive downloaded from the Twitter API). The final data frame was stored as twitter_archive_master.csv.

In the Data Analysis and Visualization, which I have interpreted as Exploratory Analysis, I have posed few questions to guide my analysis, which lead me to found strong evidence of:

Seasonality in the number of tweets along the week and along the year;
A positive correlation between the number of retweets and the number of favourites, and;
No correlation between the algorithms output used to predict the dog breed.
Finally, the Project also has other deliverables, which could be accessed by the following links:

Act Report, and;
Wrangle Report.
